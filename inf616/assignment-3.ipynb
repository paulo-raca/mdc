{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-616 - Tarefa 3\n",
    "\n",
    "Professor: Alexandre Ferreira -- melloferreira@ic.unicamp.br  \n",
    "Monitor: Lucas David -- ra188972@students.ic.unicamp.br\n",
    "\n",
    "Instituto de Computação - Unicamp  \n",
    "2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O codigo abaixo ira baixar e carregar o conjunto `spambase`.\n",
    "# Leia sobre este conjunto aqui: https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "\n",
    "target_names = ['not-spam', 'spam']\n",
    "label_field = 'label'\n",
    "attributes = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
    "              'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
    "              'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "              'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
    "              'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "              'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
    "              'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
    "              'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
    "              'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "              'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "              'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
    "              'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "              'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$',\n",
    "              'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest',\n",
    "              'capital_run_length_total', label_field]\n",
    "features = [a for a in attributes if a != 'label']\n",
    "\n",
    "d = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data',\n",
    "                header=None, names=attributes, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x, y, classes):\n",
    "    \"\"\"Descreve um conjunto de dados.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras no conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param classes: list, uma lista com os nomes de cada classe. \n",
    "    \"\"\"\n",
    "    print('amostras:', x.shape[0])\n",
    "    print('características:', x.shape[1])\n",
    "\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    print('frequência das classes:', dict(zip(classes, counts)))\n",
    "\n",
    "def show_datasets(x, y, title):\n",
    "    \"\"\"Encontra um \"embedding\" de um conjunto que alinha as direções\n",
    "       de maximiza separação das amostras com os eixos da base canônica.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras do conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param title: str, o titulo do conjunto a ser exibido.\n",
    "    \"\"\"\n",
    "    e = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PCA(n_components=2)\n",
    "    ).fit_transform(x)\n",
    "\n",
    "    _ = plt.figure(figsize=(12, 6))\n",
    "    _ = plt.scatter(e[:, 0], e[:, 1], c=y)\n",
    "    _ = plt.title(title)\n",
    "    _ = plt.axis('off')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(d[features], d['label'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1821)\n",
    "\n",
    "# Seleciona 10% dos spams.\n",
    "p, = np.where(y_train == 1)\n",
    "np.random.shuffle(p)\n",
    "p = p[:int(.1 * len(p))]\n",
    "# Encontra os indices em treino que pertencem aos 10% selecionados.\n",
    "p = np.in1d(np.arange(len(y_train)), p)\n",
    "# Seleciona todos os nao-spam ou os 10% spams selecionados.\n",
    "p = (y_train == 0) | p\n",
    "# Filtra o conjunto de treino, mantendo somente os selecionados.\n",
    "x_train, y_train = x_train[p], y_train[p]\n",
    "\n",
    "print('Conjunto Spambase treino:')\n",
    "describe(x_train, y_train, target_names)\n",
    "print('Conjunto Spambase test:')\n",
    "describe(x_test, y_test, target_names)\n",
    "show_datasets(x_train, y_train, 'train')\n",
    "show_datasets(x_test, y_test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizando tudo o que você aprendeu até aqui (e.g. CV, otimização de hiper-parâmetros, regularização), defina e treine um estimador para este problema. Avalie seu estimador sobre o conjunto de teste.**\n",
    "\n",
    "Dica: vários estimadores possuem regularizadores implementados internamente, expondo somente um parâmetro a ser ajustado. Exemplos: `KNeighborsClassifier`, `RandomForestClassifier`, `SVC`, `MLPClassifier`, `SGDClassifier`, `Perceptron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "params = [\n",
    "    {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['linear', 'rbf'],\n",
    "    }, {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__degree': range(2,5)\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearch = GridSearchCV(model, params, cv=2, n_jobs=4).fit(x_train, y_train)\n",
    "print(f'Best Estimator: {gridsearch.best_params_}')\n",
    "ŷ_test = gridsearch.best_estimator_.predict(x_test)\n",
    "print(f'Precision = {metrics.precision_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "print(f'Recall = {metrics.recall_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "print(f'F1 = {metrics.f1_score(y_true = y_test, y_pred = ŷ_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize uma ou mais técnicas da biblioteca imbalanced-learn e compare os resultados com os obtidos acima**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "params = [\n",
    "    {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['linear', 'rbf'],\n",
    "    }, {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__degree': range(2,5)\n",
    "    }\n",
    "]\n",
    "\n",
    "for balancer_class in [RandomOverSampler, SMOTE, ADASYN]:\n",
    "    print(f'Conjunto Spambase apos balanceamento {balancer_class.__name__}:')\n",
    "    balancer = balancer_class(random_state=0)\n",
    "    x_resampled_train, y_resampled_train = balancer.fit_sample(x_train, y_train)\n",
    "\n",
    "    describe(x_resampled_train, y_resampled_train, target_names)\n",
    "    show_datasets(x_resampled_train, y_resampled_train, 'resampled train')\n",
    "    \n",
    "    gridsearch = GridSearchCV(model, params, cv=2, n_jobs=4).fit(x_resampled_train, y_resampled_train)\n",
    "    print(f'Best Estimator: {gridsearch.best_params_}')\n",
    "    ŷ_test = gridsearch.best_estimator_.predict(x_test)\n",
    "    print(f'Precision = {metrics.precision_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "    print(f'Recall = {metrics.recall_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "    print(f'F1 = {metrics.f1_score(y_true = y_test, y_pred = ŷ_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Use 'class_weight': ['balanced'] instead of balancing with fake data\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "params = [\n",
    "    {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__class_weight': ['balanced'],\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['linear', 'rbf'],\n",
    "    }, {\n",
    "        #'pca__n_components': range(1, len(features) + 1),\n",
    "        'svc__class_weight': ['balanced'],\n",
    "        'svc__C': [10**x for x in range(-3, 4)],\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__degree': range(2,5)\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearch = GridSearchCV(model, params, cv=2, n_jobs=4).fit(x_train, y_train)\n",
    "print(f'Best Estimator: {gridsearch.best_params_}')\n",
    "ŷ_test = gridsearch.best_estimator_.predict(x_test)\n",
    "print(f'Precision = {metrics.precision_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "print(f'Recall = {metrics.recall_score(y_true = y_test, y_pred = ŷ_test):.3f}')\n",
    "print(f'F1 = {metrics.f1_score(y_true = y_test, y_pred = ŷ_test):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
